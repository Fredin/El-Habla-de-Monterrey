substr("h11", 2, 4)
substr("h11", 1, 1)
?eval
eval(nombres(1))
eval(nombres[1])
assign(nombres[1])
grupos<- list()
subsetter <- function(sexo, edad, edu){
x<-hablaMty[meta(hablaMty, tag = "sexo") == sexo &
meta(hablaMty, tag = "grupo_edad") == edad &
meta(hablaMty, tag = "nivel_edu") == edu]
return(x)
}
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[i] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
warnings()
grupos
grupos<- list()
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[[i]] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
grupos <- list(h11, h12, h13, h21, h22, h23, h31, h32, h33, m11, m12, m13, m21,
m22, m23, m31, m32, m33)
grupos<- list()
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[[i]] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
grupos
palabrasParo <-read.table("~/hablaMty/stopwords/palabrasParo.txt",
encoding = "UTF-8", colClasses = "character")
for (i in seq_along(grupos)){
tdm <- TermDocumentMatrix(grupos[[i]],
control = list(removePunctuation = TRUE,
stopwords = c("pos","allá","digo","nomás","mjm", palabrasParo[,1]),
removeNumbers = TRUE, tolower = TRUE,
content_transformer(stripWhitespace)))
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
dm <- data.frame(word = names(word_freqs), freq = word_freqs)
top <- dm[1:100,]
png(paste0("~/hablaMty/img/",nombres[i],".png"), width=12, height=8,
units="in", res = 300)
wordcloud(top$word, top$freq, random.order=FALSE,
colors = brewer.pal(8, "Dark2"))
dev.off()
}
head(m)
grupos[[1]]
grupos<- list()
nombres <- c("H11", "H12", "H13", "H21", "H22", "H23", "H31", "H32", "H33",
"M11", "M12", "M13", "M21", "M22", "M23", "M31", "M32", "M33")
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[[i]] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
H33
H33[1]
H33[[1]]
inspect(H33[[1]])
H33[[1]]$content
hablaMty <- Corpus(DirSource("~/hablaMty/TEXT"),
readerControl = list(reader = readPlain,
language = "spa",
load = FALSE,
encoding = "UTF-8"))
##### Setting metadata tags ######
for (i in seq_along(hablaMty)) {
splitID <- strsplit(meta(hablaMty[[i]], "id"), "")
meta(hablaMty[[i]], tag = "sexo") <- splitID[[1]][6]
meta(hablaMty[[i]], tag = "grupo_edad") <- splitID[[1]][7]
meta(hablaMty[[i]], tag = "nivel_edu") <- splitID[[1]][8]
}
##### Unicode fixing #####
fixUnicode<- function (x){
x<-stri_escape_unicode(x)
x<-gsub("\\u00c3\\u00a1", "\\u00e1", x, fixed = TRUE) # a w acute accent
x<-gsub("\\u00c3\\u00a9", "\\u00e9", x, fixed = TRUE) # e w acute accent
x<-gsub("\\u00c3\\u00ad", "\\u00ed", x, fixed = TRUE) # i w acute accent
x<-gsub("\\u00c3\\u00b3", "\\u00f3", x, fixed = TRUE) # o w acute accent
x<-gsub("\\u00c3\\u00ba", "\\u00fa", x, fixed = TRUE) # u w acute accent
x<-gsub("\\u00c3\\u00b1", "\\u00f1", x, fixed = TRUE) # n w tilde
x<-gsub("\\u00c2\\u00bf", "\\u00bf", x, fixed = TRUE) # inverted questionm.
x<-gsub("\\u00c2\\u00a1", "\\u00a1", x, fixed = TRUE) # inverted bang
x<-gsub("\\u00e2\\u20ac\\u0153", "\\u201c", x, fixed = TRUE) # o.d.quot. m.
x<-gsub("\\u00e2\\u20ac\\u009d", "\\u201d", x, fixed = TRUE) # c.d.quot. m.
x<-gsub("\\u00c3\\u00bc", "\\u00fc", x, fixed = TRUE) # u w dieresis
x<-gsub("\\u00e2\\u20ac\\u2122", "'", x, fixed = TRUE) # u w dieresis
x<-stri_unescape_unicode(x)
return(x)
}
f <- content_transformer(function(x, pattern) gsub(pattern, "", x))
###### Transformations #######
hablaMty <- tm_map(hablaMty, f, "^E:.*") # get rid of interviewer
hablaMty <- tm_map(hablaMty, f, "<.*>") # get rid of annotations
hablaMty <- tm_map(hablaMty, content_transformer(fixUnicode))
####### Subsetting by groups #######
subsetter <- function(sexo, edad, edu){
x<-hablaMty[meta(hablaMty, tag = "sexo") == sexo &
meta(hablaMty, tag = "grupo_edad") == edad &
meta(hablaMty, tag = "nivel_edu") == edu]
return(x)
}
nombres <- c("H11", "H12", "H13", "H21", "H22", "H23", "H31", "H32", "H33",
"M11", "M12", "M13", "M21", "M22", "M23", "M31", "M32", "M33")
grupos<- list()
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[[i]] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
palabrasParo <-read.table("~/hablaMty/stopwords/palabrasParo.txt",
encoding = "UTF-8", colClasses = "character")
for (i in seq_along(grupos)){
tdm <- TermDocumentMatrix(grupos[[i]],
control = list(removePunctuation = TRUE,
stopwords = c("pos","allá","digo","nomás","mjm", palabrasParo[,1]),
removeNumbers = TRUE, tolower = TRUE,
content_transformer(stripWhitespace)))
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
dm <- data.frame(word = names(word_freqs), freq = word_freqs)
top <- dm[1:100,]
png(paste0("~/hablaMty/img/",nombres[i],".png"), width=12, height=8,
units="in", res = 300)
wordcloud(top$word, top$freq, random.order=FALSE,
colors = brewer.pal(8, "Dark2"))
dev.off()
}
head(splitID)
tdm <- TermDocumentMatrix(grupos[[1]],
control = list(removePunctuation = TRUE,
stopwords = c("pos","allá","digo","nomás","mjm", palabrasParo[,1]),
removeNumbers = TRUE, tolower = TRUE,
content_transformer(stripWhitespace)))
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
dm <- data.frame(word = names(word_freqs), freq = word_freqs)
top <- dm[1:100,]
png(paste0("~/hablaMty/img/",nombres[1],".png"), width=12, height=8,
units="in", res = 300)
wordcloud(top$word, top$freq, random.order=FALSE,
colors = brewer.pal(8, "Dark2"))
dev.off()
nombres[1]
install.packages("devtools")
require(devtools)
install_url("http://www.omegahat.org/Rstem/Rstem_0.4-1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
library(devtools)
install.packages("devtools")
require(devtools)
install_url("http://www.omegahat.org/Rstem/Rstem_0.4-1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
install_url("http://www.omegahat.org/Rstem/Rstem_0.4-1.tar.gz")
install_url("http://www.omegahat.net/Rstem/Rstem_0.4-1.tar.gz")
detach("package:devtools", unload=TRUE)
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
require(devtools)
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install.packages("slam")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
libary(sentiment)
library(sentiment)
?classify_emotion
data(emotions)
head(emotions)
tail(emotions)
?sentiment
??sentiment
library(sentiment)
install.packages("tm.plugin.sentiment", repos="http://R-Forge.R-project.org")
library(tm.plugin.sentiment)
?install.packages
install_github("mannau/tm.plugin.sentiment")
library(tm.plugin.sentiment)
# retrieve corpus
require(tm.plugin.webmining)
corp = WebCorpus(GoogleFinanceSource("AAPL"))
# score corpus
corp <- score(corp)
sentixts <- metaXTS(corp)
# chart sentiment scores
chartSentiment(sentixts)
install.packages("tm.plugin.webmining")
install.packages("tm.plugin.sentiment")
require(tm.plugin.webmining)
corp = WebCorpus(GoogleFinanceSource("AAPL"))
# score corpus
corp <- score(corp)
sentixts <- metaXTS(corp)
# chart sentiment scores
chartSentiment(sentixts)
install_github("mannau/tm.plugin.sentiment")
library(tm)
library(stringi)
library(wordcloud)
##### Create cropus ######
hablaMty <- Corpus(DirSource("~/hablaMty/TEXT"),
readerControl = list(reader = readPlain,
language = "spa",
load = FALSE,
encoding = "UTF-8"))
##### Setting metadata tags ######
for (i in seq_along(hablaMty)) {
splitID <- strsplit(meta(hablaMty[[i]], "id"), "")
meta(hablaMty[[i]], tag = "sexo") <- splitID[[1]][6]
meta(hablaMty[[i]], tag = "grupo_edad") <- splitID[[1]][7]
meta(hablaMty[[i]], tag = "nivel_edu") <- splitID[[1]][8]
}
##### Unicode fixing #####
fixUnicode<- function (x){
x<-stri_escape_unicode(x)
x<-gsub("\\u00c3\\u00a1", "\\u00e1", x, fixed = TRUE) # a w acute accent
x<-gsub("\\u00c3\\u00a9", "\\u00e9", x, fixed = TRUE) # e w acute accent
x<-gsub("\\u00c3\\u00ad", "\\u00ed", x, fixed = TRUE) # i w acute accent
x<-gsub("\\u00c3\\u00b3", "\\u00f3", x, fixed = TRUE) # o w acute accent
x<-gsub("\\u00c3\\u00ba", "\\u00fa", x, fixed = TRUE) # u w acute accent
x<-gsub("\\u00c3\\u00b1", "\\u00f1", x, fixed = TRUE) # n w tilde
x<-gsub("\\u00c2\\u00bf", "\\u00bf", x, fixed = TRUE) # inverted questionm.
x<-gsub("\\u00c2\\u00a1", "\\u00a1", x, fixed = TRUE) # inverted bang
x<-gsub("\\u00e2\\u20ac\\u0153", "\\u201c", x, fixed = TRUE) # o.d.quot. m.
x<-gsub("\\u00e2\\u20ac\\u009d", "\\u201d", x, fixed = TRUE) # c.d.quot. m.
x<-gsub("\\u00c3\\u00bc", "\\u00fc", x, fixed = TRUE) # u w dieresis
x<-gsub("\\u00e2\\u20ac\\u2122", "'", x, fixed = TRUE) # u w dieresis
x<-stri_unescape_unicode(x)
return(x)
}
f <- content_transformer(function(x, pattern) gsub(pattern, "", x))
###### Transformations #######
hablaMty <- tm_map(hablaMty, f, "^E:.*") # get rid of interviewer
hablaMty <- tm_map(hablaMty, f, "<.*>") # get rid of annotations
hablaMty <- tm_map(hablaMty, content_transformer(fixUnicode))
####### Subsetting by groups #######
subsetter <- function(sexo, edad, edu){
x<-hablaMty[meta(hablaMty, tag = "sexo") == sexo &
meta(hablaMty, tag = "grupo_edad") == edad &
meta(hablaMty, tag = "nivel_edu") == edu]
return(x)
}
nombres <- c("H11", "H12", "H13", "H21", "H22", "H23", "H31", "H32", "H33",
"M11", "M12", "M13", "M21", "M22", "M23", "M31", "M32", "M33")
grupos<- list()
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[[i]] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
palabrasParo <-read.table("~/hablaMty/stopwords/palabrasParo.txt",
encoding = "UTF-8", colClasses = "character")
meta(habalMty)
meta(hablaMty)
meta(hablaMty[[1]])
meta(hablaMty[[1]],"id")
strsplit(meta(hablaMty[[1]],"id"),"")
grep("demonios",hablaMty)
grep("demonios",hablaMty[[1]])
grep("salud",hablaMty[[1]])
hablaMty[[1]][493]
hablaMty[[1]][829]
inspect(hablaMty[[1]][829])
grep("hola",hablaMty[[1]])
grep("buen",hablaMty[[1]])
hablaMty[[1]]$content
coso<-hablaMty[[1]]$content
grep("buen",hablaMty[[1]])
coso[161]
coso[405]
getText <- function (x, lema, ignore.case = TRUE) {
mydf <- data.frame(NULL)
for (i in seq_along(x)){
linea <-grep(lema, as.character(x[[i]]), ignore.case = ignore.case)
texto <- grep(lema, as.character(x[[i]]), ignore.case = ignore.case,
value = TRUE)
id <- rep(deparse(substitute(x)), length(linea))
numDoc <- rep(i, length(linea))
tmpdf <- data.frame(texto, id, numDoc, linea)
mydf <- rbind(mydf, tmpdf)
}
return(mydf)
}
getText(hablaMty,"puto")
getText(M32,"puto")
getText(M12,"puto")
getText(M12,"día")
seq_along(H11)
seq_along(M11)
hablaMty[[1]]$content
M11[317]
M11[[1]]
M11[[1]][317]
M11[[1]][317]$content
M11[[1]]$content[317]
M12[[1]]$content[317]
library(tm)
library(stringi)
library(wordcloud)
hablaMty <- Corpus(DirSource("~/hablaMty/TEXT"),
readerControl = list(reader = readPlain,
language = "spa",
load = FALSE,
encoding = "UTF-8"))
for (i in seq_along(hablaMty)) {
splitID <- strsplit(meta(hablaMty[[i]], "id"), "")
meta(hablaMty[[i]], tag = "sexo") <- splitID[[1]][6]
meta(hablaMty[[i]], tag = "grupo_edad") <- splitID[[1]][7]
meta(hablaMty[[i]], tag = "nivel_edu") <- splitID[[1]][8]
}
fixUnicode<- content_transformer(function (x){
x<-stri_escape_unicode(x)
x<-gsub("\\u00c3\\u00a1", "\\u00e1", x, fixed = TRUE) # a w acute accent
x<-gsub("\\u00c3\\u00a9", "\\u00e9", x, fixed = TRUE) # e w acute accent
x<-gsub("\\u00c3\\u00ad", "\\u00ed", x, fixed = TRUE) # i w acute accent
x<-gsub("\\u00c3\\u00b3", "\\u00f3", x, fixed = TRUE) # o w acute accent
x<-gsub("\\u00c3\\u00ba", "\\u00fa", x, fixed = TRUE) # u w acute accent
x<-gsub("\\u00c3\\u00b1", "\\u00f1", x, fixed = TRUE) # n w tilde
x<-gsub("\\u00c2\\u00bf", "\\u00bf", x, fixed = TRUE) # inverted questionm.
x<-gsub("\\u00c2\\u00a1", "\\u00a1", x, fixed = TRUE) # inverted bang
x<-gsub("\\u00e2\\u20ac\\u0153", "\\u201c", x, fixed = TRUE) # o.d.quot. m.
x<-gsub("\\u00e2\\u20ac\\u009d", "\\u201d", x, fixed = TRUE) # c.d.quot. m.
x<-gsub("\\u00c3\\u00bc", "\\u00fc", x, fixed = TRUE) # u w dieresis
x<-gsub("\\u00e2\\u20ac\\u2122", "'", x, fixed = TRUE) # u w dieresis
x<-stri_unescape_unicode(x)
return(x)
})
f <- content_transformer(function(x, pattern) gsub(pattern, "", x))
hablaMty <- tm_map(hablaMty, f, "^E:.*") # get rid of interviewer
hablaMty <- tm_map(hablaMty, f, "<.*>") # get rid of annotations
hablaMty <- tm_map(hablaMty, fixUnicode)
subsetter <- function(sexo, edad, edu){
x<-hablaMty[meta(hablaMty, tag = "sexo") == sexo &
meta(hablaMty, tag = "grupo_edad") == edad &
meta(hablaMty, tag = "nivel_edu") == edu]
return(x)
}
nombres <- c("H11", "H12", "H13", "H21", "H22", "H23", "H31", "H32", "H33",
"M11", "M12", "M13", "M21", "M22", "M23", "M31", "M32", "M33")
grupos<- list()
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[[i]] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
palabrasParo <-read.table("~/hablaMty/stopwords/palabrasParo.txt",
encoding = "UTF-8", colClasses = "character")
for (i in seq_along(grupos)){
tdm <- TermDocumentMatrix(grupos[[i]],
control = list(removePunctuation = TRUE,
stopwords = c("pos","allá","digo","nomás","mjm", palabrasParo[,1]),
removeNumbers = TRUE, tolower = TRUE,
content_transformer(stripWhitespace)))
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
dm <- data.frame(word = names(word_freqs), freq = word_freqs)
top <- dm[1:100,]
png(paste0("~/hablaMty/img/",nombres[i],".png"), width=12, height=8,
units="in", res = 300)
wordcloud(top$word, top$freq, random.order=FALSE,
colors = brewer.pal(8, "Dark2"))
dev.off()
}
getwd()
hablaMty <- Corpus(DirSource("~/hablaMty/text"),
readerControl = list(reader = readPlain,
language = "spa",
load = FALSE,
encoding = "UTF-8"))
library(tm)
library(stringi)
library(wordcloud)
hablaMty <- Corpus(DirSource("~/hablaMty/text"),
readerControl = list(reader = readPlain,
language = "spa",
load = FALSE,
encoding = "UTF-8"))
hablaMty <- Corpus(DirSource("~/hablaMty/text"),
readerControl = list(reader = readPlain,
language = "spa",
load = FALSE,
encoding = "UTF-8"))
for (i in seq_along(hablaMty)) {
splitID <- strsplit(meta(hablaMty[[i]], "id"), "")
meta(hablaMty[[i]], tag = "sexo") <- splitID[[1]][6]
meta(hablaMty[[i]], tag = "grupo_edad") <- splitID[[1]][7]
meta(hablaMty[[i]], tag = "nivel_edu") <- splitID[[1]][8]
}
##### Unicode fixing functions#####
fixUnicode<- content_transformer(function (x){
x<-stri_escape_unicode(x)
x<-gsub("\\u00c3\\u00a1", "\\u00e1", x, fixed = TRUE) # a w acute accent
x<-gsub("\\u00c3\\u00a9", "\\u00e9", x, fixed = TRUE) # e w acute accent
x<-gsub("\\u00c3\\u00ad", "\\u00ed", x, fixed = TRUE) # i w acute accent
x<-gsub("\\u00c3\\u00b3", "\\u00f3", x, fixed = TRUE) # o w acute accent
x<-gsub("\\u00c3\\u00ba", "\\u00fa", x, fixed = TRUE) # u w acute accent
x<-gsub("\\u00c3\\u00b1", "\\u00f1", x, fixed = TRUE) # n w tilde
x<-gsub("\\u00c2\\u00bf", "\\u00bf", x, fixed = TRUE) # inverted questionm.
x<-gsub("\\u00c2\\u00a1", "\\u00a1", x, fixed = TRUE) # inverted bang
x<-gsub("\\u00e2\\u20ac\\u0153", "\\u201c", x, fixed = TRUE) # o.d.quot. m.
x<-gsub("\\u00e2\\u20ac\\u009d", "\\u201d", x, fixed = TRUE) # c.d.quot. m.
x<-gsub("\\u00c3\\u00bc", "\\u00fc", x, fixed = TRUE) # u w dieresis
x<-gsub("\\u00e2\\u20ac\\u2122", "'", x, fixed = TRUE) # u w dieresis
x<-stri_unescape_unicode(x)
return(x)
})
f <- content_transformer(function(x, pattern) gsub(pattern, "", x))
###### Transformations #######
hablaMty <- tm_map(hablaMty, f, "^E:.*") # get rid of interviewer
hablaMty <- tm_map(hablaMty, f, "<.*>") # get rid of annotations
hablaMty <- tm_map(hablaMty, fixUnicode)
####### Subsetting by groups #######
subsetter <- function(sexo, edad, edu){
x<-hablaMty[meta(hablaMty, tag = "sexo") == sexo &
meta(hablaMty, tag = "grupo_edad") == edad &
meta(hablaMty, tag = "nivel_edu") == edu]
return(x)
}
nombres <- c("H11", "H12", "H13", "H21", "H22", "H23", "H31", "H32", "H33",
"M11", "M12", "M13", "M21", "M22", "M23", "M31", "M32", "M33")
grupos<- list()
for (i in seq_along(nombres)){
sexo<-substr(nombres[i],1,1)
edad<-substr(nombres[i],2,2)
edu<-substr(nombres[i],3,3)
grupos[[i]] <- assign(nombres[i], subsetter(sexo,edad,edu))
}
getText <- function (x, lema, ignore.case = TRUE) {
mydf <- data.frame(NULL)
for (i in seq_along(x)){
linea <-grep(lema, as.character(x[[i]]), ignore.case = ignore.case)
texto <- grep(lema, as.character(x[[i]]), ignore.case = ignore.case,
value = T)
id <- rep(deparse(substitute(x)), length(linea))
numDoc <- rep(i, length(linea))
tmpdf <- data.frame(texto, id, numDoc, linea)
mydf <- rbind(mydf, tmpdf)
}
return(mydf)
}
getText(M32,"hola")
getText(H11,"chingado")
installed.packages
installed.packages()
packrat::init()
install.packages("tm.plugin.sentiment")
getText(hablaMty,"pinche")
getText(hablaMty,"pinche")->pinche
View(pinche)
getText(H11,"pinche")->pincheH11
View(pincheH11)
getText(H11,"ching+[a-z]")->chingH11
View(chingH11)
?rm
rm(pinche,pincheH11)
chingH11[51,1]
getText <- function (x, lema, ignore.case = TRUE) {
mydf <- data.frame(NULL)
for (i in seq_along(x)){
linea <-grep(lema, as.character(x[[i]]), ignore.case = ignore.case)
texto <- as.character(grep(lema, as.character(x[[i]]), ignore.case = ignore.case,
value = T))
id <- rep(deparse(substitute(x)), length(linea))
numDoc <- rep(i, length(linea))
tmpdf <- data.frame(texto, id, numDoc, linea)
mydf <- rbind(mydf, tmpdf)
}
return(mydf)
}
getText(H11,"ching+[a-z]")->chingH11
chingH11[51,1]
class(chingH11[51,1])
class(chingH11[51,2])
class(chingH11[51,3])
class(chingH11[51,4])
?deparse
getText <- function (x, lema, ignore.case = TRUE) {
mydf <- data.frame(NULL)
for (i in seq_along(x)){
linea <-grep(lema, as.character(x[[i]]), ignore.case = ignore.case)
texto <-grep(lema, as.character(x[[i]]), ignore.case = ignore.case,
value = T)
grupo <- rep(deparse(substitute(x)), length(linea))
numDoc <- rep(i, length(linea))
tmpdf <- data.frame(as.character(texto), grupo, numDoc, linea)
mydf <- rbind(mydf, tmpdf)
}
return(mydf)
}
getText(H11,"ching+[a-z]")->chingH11
class(chingH11[1,:])
class(chingH11[1,])
class(chingH11[1,1])
class(chingH11[1-51,1])
class(chingH11[,1])
chingH11[,1]
rm(chingH11)
